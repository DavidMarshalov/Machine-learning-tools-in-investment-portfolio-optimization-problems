{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c244355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\lib\\site-packages\\yfinance\\base.py:48: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  _empty_series = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "import math\n",
    "import statistics\n",
    "import random\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05379614",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = pd.read_excel(r\"C:\\Users\\david\\Desktop\\дипломная\\код\\data\\selected_companies.xlsx\")\n",
    "   \n",
    "prices = pd.read_excel(r\"C:\\Users\\david\\Desktop\\дипломная\\код\\data\\data_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4b3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сделаем дату индексом \n",
    "prices.set_index(\"Date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dfa30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#корректировка тикеров\n",
    "tickers = tickers.applymap(lambda x: x.split(\".\")[0] if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb0e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#поиск значений которых нет в prices и их загрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2678f455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten преобразует массив в одномерный\n",
    "values_for_dawnload = list(set(tickers.values.flatten().tolist()) - set(prices.columns))\n",
    "\n",
    "for value_for_del in values_for_dawnload:\n",
    "    if isinstance(value_for_del, float):\n",
    "        values_for_dawnload.remove(value_for_del)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09a7e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  49 of 49 completed\n"
     ]
    }
   ],
   "source": [
    "#загрузка недостающих данных \n",
    "company_added = yf.download(values_for_dawnload, start=\"2010-03-04\", end=\"2024-01-29\")[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f5aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = pd.Timestamp('2012-05-18')\n",
    "\n",
    "#делаю срез до заданной даты\n",
    "filtered_df = company_added[company_added.index >= cutoff_date]\n",
    "#список удаленных компаний\n",
    "removed_columns = []\n",
    "\n",
    "#проходжу по всем столбцам и проверяю на наличие nan значений\n",
    "\n",
    "for column in filtered_df.columns:\n",
    "    if filtered_df[column].isna().any():\n",
    "        removed_columns.append(column)\n",
    "        company_added.drop(column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72eb1483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#очищаю до до cutoff_date\n",
    "company_added.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c2e1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#добавляю отсутствующие значения \n",
    "\n",
    "prices = pd.merge(prices, company_added, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36d104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2141ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  3 of 3 completed\n"
     ]
    }
   ],
   "source": [
    "#добавляем голду неть и спишку в prices \n",
    "tick_download = [\"GC=F\", \"BZ=F\", \"^GSPC\"]\n",
    "data = yf.download(tick_download, start=\"2010-03-04\", end=\"2024-01-29\")[\"Close\"]\n",
    "\n",
    "\n",
    "#переименуем названия столбцов\n",
    "data.rename(columns={\"GC=F\":\"Gold\",\n",
    "                     \"BZ=F\":\"Brent\",\n",
    "                     \"^GSPC\":\"SP_500\"}, inplace=True)\n",
    "\n",
    "#обьединяем фреймы\n",
    "\n",
    "prices = pd.merge(prices, data, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8df6490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаляю Nan вэлью\n",
    "prices.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ad1c15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PG</td>\n",
       "      <td>CSX</td>\n",
       "      <td>PG</td>\n",
       "      <td>PG</td>\n",
       "      <td>BDX</td>\n",
       "      <td>IEX</td>\n",
       "      <td>CSL</td>\n",
       "      <td>XYL</td>\n",
       "      <td>ELV</td>\n",
       "      <td>CTSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PGR</td>\n",
       "      <td>TSN</td>\n",
       "      <td>CSL</td>\n",
       "      <td>A</td>\n",
       "      <td>SWK</td>\n",
       "      <td>A</td>\n",
       "      <td>CTSH</td>\n",
       "      <td>CTSH</td>\n",
       "      <td>BIIB</td>\n",
       "      <td>BLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROP</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>A</td>\n",
       "      <td>SCHW</td>\n",
       "      <td>MDLZ</td>\n",
       "      <td>TXRH</td>\n",
       "      <td>IEX</td>\n",
       "      <td>IEX</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>TKO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DG</td>\n",
       "      <td>DRI</td>\n",
       "      <td>SWK</td>\n",
       "      <td>SWK</td>\n",
       "      <td>ELV</td>\n",
       "      <td>TDY</td>\n",
       "      <td>BLK</td>\n",
       "      <td>BLK</td>\n",
       "      <td>DLTR</td>\n",
       "      <td>COP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TDY</td>\n",
       "      <td>EXPE</td>\n",
       "      <td>ENTG</td>\n",
       "      <td>TXRH</td>\n",
       "      <td>ROP</td>\n",
       "      <td>WSO</td>\n",
       "      <td>SWK</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>WMT</td>\n",
       "      <td>DOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SNA</td>\n",
       "      <td>RL</td>\n",
       "      <td>TXRH</td>\n",
       "      <td>EME</td>\n",
       "      <td>DOC</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>DRI</td>\n",
       "      <td>DLTR</td>\n",
       "      <td>AME</td>\n",
       "      <td>EMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TFX</td>\n",
       "      <td>WMT</td>\n",
       "      <td>EXPE</td>\n",
       "      <td>EXPE</td>\n",
       "      <td>AJG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EME</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>CMI</td>\n",
       "      <td>HOLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RVTY</td>\n",
       "      <td>DKS</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>IFF</td>\n",
       "      <td>SNPS</td>\n",
       "      <td>NDAQ</td>\n",
       "      <td>TFX</td>\n",
       "      <td>DHR</td>\n",
       "      <td>SNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNPS</td>\n",
       "      <td>EPD</td>\n",
       "      <td>TFX</td>\n",
       "      <td>ODFL</td>\n",
       "      <td>FIS</td>\n",
       "      <td>APD</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>BSX</td>\n",
       "      <td>ITT</td>\n",
       "      <td>GD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CF</td>\n",
       "      <td>STZ</td>\n",
       "      <td>ODFL</td>\n",
       "      <td>WBA</td>\n",
       "      <td>NDAQ</td>\n",
       "      <td>HRL</td>\n",
       "      <td>CRM</td>\n",
       "      <td>AME</td>\n",
       "      <td>APD</td>\n",
       "      <td>TROW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CTAS</td>\n",
       "      <td>BEN</td>\n",
       "      <td>WBA</td>\n",
       "      <td>ALB</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>CSL</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUM</td>\n",
       "      <td>CBRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>DKS</td>\n",
       "      <td>AME</td>\n",
       "      <td>NSC</td>\n",
       "      <td>ROP</td>\n",
       "      <td>AXP</td>\n",
       "      <td>ITT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CI</td>\n",
       "      <td>JNPR</td>\n",
       "      <td>SNPS</td>\n",
       "      <td>SNPS</td>\n",
       "      <td>TMO</td>\n",
       "      <td>DGX</td>\n",
       "      <td>BRO</td>\n",
       "      <td>APD</td>\n",
       "      <td>NSC</td>\n",
       "      <td>ITT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ON</td>\n",
       "      <td>DHI</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ITT</td>\n",
       "      <td>WMT</td>\n",
       "      <td>AJG</td>\n",
       "      <td>AME</td>\n",
       "      <td>AKAM</td>\n",
       "      <td>LDOS</td>\n",
       "      <td>LYV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SSNC</td>\n",
       "      <td>RCL</td>\n",
       "      <td>GE</td>\n",
       "      <td>BAX</td>\n",
       "      <td>AME</td>\n",
       "      <td>DIS</td>\n",
       "      <td>ADI</td>\n",
       "      <td>JBHT</td>\n",
       "      <td>RPM</td>\n",
       "      <td>HUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CNC</td>\n",
       "      <td>DECK</td>\n",
       "      <td>HUBB</td>\n",
       "      <td>APD</td>\n",
       "      <td>RVTY</td>\n",
       "      <td>NDAQ</td>\n",
       "      <td>DHR</td>\n",
       "      <td>AOS</td>\n",
       "      <td>UTHR</td>\n",
       "      <td>INTU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SAIA</td>\n",
       "      <td>PG</td>\n",
       "      <td>HUM</td>\n",
       "      <td>HRL</td>\n",
       "      <td>HAL</td>\n",
       "      <td>DLTR</td>\n",
       "      <td>PCAR</td>\n",
       "      <td>CBRE</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ET</td>\n",
       "      <td>IEX</td>\n",
       "      <td>PH</td>\n",
       "      <td>HUBB</td>\n",
       "      <td>DECK</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>CBRE</td>\n",
       "      <td>SAIA</td>\n",
       "      <td>SPGI</td>\n",
       "      <td>WSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CSX</td>\n",
       "      <td>ROP</td>\n",
       "      <td>AKAM</td>\n",
       "      <td>HUM</td>\n",
       "      <td>IEX</td>\n",
       "      <td>TMO</td>\n",
       "      <td>PKG</td>\n",
       "      <td>EA</td>\n",
       "      <td>TFX</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DRI</td>\n",
       "      <td>TXRH</td>\n",
       "      <td>CSX</td>\n",
       "      <td>AKAM</td>\n",
       "      <td>A</td>\n",
       "      <td>WMT</td>\n",
       "      <td>APD</td>\n",
       "      <td>MKC</td>\n",
       "      <td>GD</td>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CAT</td>\n",
       "      <td>AZPN</td>\n",
       "      <td>XYL</td>\n",
       "      <td>TECH</td>\n",
       "      <td>TXRH</td>\n",
       "      <td>BSX</td>\n",
       "      <td>HRL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TROW</td>\n",
       "      <td>SNPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WTRG</td>\n",
       "      <td>HEI</td>\n",
       "      <td>SCHW</td>\n",
       "      <td>TKO</td>\n",
       "      <td>EXPE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PWR</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ALGN</td>\n",
       "      <td>DIS</td>\n",
       "      <td>WTRG</td>\n",
       "      <td>ISRG</td>\n",
       "      <td>WSO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSX</td>\n",
       "      <td>NSC</td>\n",
       "      <td>WRB</td>\n",
       "      <td>MKC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>IP</td>\n",
       "      <td>ANSS</td>\n",
       "      <td>SCCO</td>\n",
       "      <td>CNP</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>AME</td>\n",
       "      <td>BMY</td>\n",
       "      <td>BAX</td>\n",
       "      <td>AKAM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AME</td>\n",
       "      <td>DLTR</td>\n",
       "      <td>DGX</td>\n",
       "      <td>DOX</td>\n",
       "      <td>ADI</td>\n",
       "      <td>RSG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SLB</td>\n",
       "      <td>WMB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CTRA</td>\n",
       "      <td>ADI</td>\n",
       "      <td>STZ</td>\n",
       "      <td>WTRG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RVTY</td>\n",
       "      <td>NOC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALGN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HOLX</td>\n",
       "      <td>FDX</td>\n",
       "      <td>LKQ</td>\n",
       "      <td>TMO</td>\n",
       "      <td>SNPS</td>\n",
       "      <td>CF</td>\n",
       "      <td>CRL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>NDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>UHS</td>\n",
       "      <td>WST</td>\n",
       "      <td>CMCSA</td>\n",
       "      <td>LDOS</td>\n",
       "      <td>BAX</td>\n",
       "      <td>GE</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CVX</td>\n",
       "      <td>NSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KMX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISRG</td>\n",
       "      <td>LKQ</td>\n",
       "      <td>HRL</td>\n",
       "      <td>ON</td>\n",
       "      <td>FBIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>META</td>\n",
       "      <td>DFS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DVA</td>\n",
       "      <td>HUBB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASY</td>\n",
       "      <td>AKAM</td>\n",
       "      <td>MCHP</td>\n",
       "      <td>DOV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>EPD</td>\n",
       "      <td>PH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CMCSA</td>\n",
       "      <td>LUV</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>NSC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAL</td>\n",
       "      <td>BAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>STZ</td>\n",
       "      <td>TECH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SSNC</td>\n",
       "      <td>LAMR</td>\n",
       "      <td>CAT</td>\n",
       "      <td>BLDR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMD</td>\n",
       "      <td>CMCSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>META</td>\n",
       "      <td>UNH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MKC</td>\n",
       "      <td>LDOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EA</td>\n",
       "      <td>SCI</td>\n",
       "      <td>NRG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SSNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>APD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GM</td>\n",
       "      <td>VZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CASY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>WM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ET</td>\n",
       "      <td>ICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ISRG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IBM</td>\n",
       "      <td>CASY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    2014   2015   2016   2017  2018   2019   2020  2021  2022   2023\n",
       "0     PG    CSX     PG     PG   BDX    IEX    CSL   XYL   ELV   CTSH\n",
       "1    PGR    TSN    CSL      A   SWK      A   CTSH  CTSH  BIIB    BLK\n",
       "2    ROP  GOOGL      A   SCHW  MDLZ   TXRH    IEX   IEX  CBOE    TKO\n",
       "3     DG    DRI    SWK    SWK   ELV    TDY    BLK   BLK  DLTR    COP\n",
       "4    TDY   EXPE   ENTG   TXRH   ROP    WSO    SWK  CBOE   WMT    DOX\n",
       "5    SNA     RL   TXRH    EME   DOC   CBOE    DRI  DLTR   AME    EMR\n",
       "6    TFX    WMT   EXPE   EXPE   AJG    NaN    EME  TRMB   CMI   HOLX\n",
       "7   RVTY    DKS   TRMB   TRMB   IFF   SNPS   NDAQ   TFX   DHR    SNA\n",
       "8   SNPS    EPD    TFX   ODFL   FIS    APD   CBOE   BSX   ITT     GD\n",
       "9     CF    STZ   ODFL    WBA  NDAQ    HRL    CRM   AME   APD   TROW\n",
       "10  CTAS    BEN    WBA    ALB  TRMB    CSL   TRMB   NaN   HUM   CBRE\n",
       "11  LRCX   NVDA    DKS    AME   NSC    ROP    AXP   ITT   NaN      J\n",
       "12    CI   JNPR   SNPS   SNPS   TMO    DGX    BRO   APD   NSC    ITT\n",
       "13    ON    DHI    ABT    ITT   WMT    AJG    AME  AKAM  LDOS    LYV\n",
       "14  SSNC    RCL     GE    BAX   AME    DIS    ADI  JBHT   RPM    HUM\n",
       "15   CNC   DECK   HUBB    APD  RVTY   NDAQ    DHR   AOS  UTHR   INTU\n",
       "16  SAIA     PG    HUM    HRL   HAL   DLTR   PCAR  CBRE  TRMB  GOOGL\n",
       "17    ET    IEX     PH   HUBB  DECK   TRMB   CBRE  SAIA  SPGI    WSO\n",
       "18   CSX    ROP   AKAM    HUM   IEX    TMO    PKG    EA   TFX   NFLX\n",
       "19   DRI   TXRH    CSX   AKAM     A    WMT    APD   MKC    GD   META\n",
       "20   CAT   AZPN    XYL   TECH  TXRH    BSX    HRL   NaN  TROW   SNPS\n",
       "21  WTRG    HEI   SCHW    TKO  EXPE    NaN   SAIA   NaN   PWR    CAG\n",
       "22  ALGN    DIS   WTRG   ISRG   WSO    NaN    CSX   NSC   WRB    MKC\n",
       "23    IP   ANSS   SCCO    CNP  CBOE    AME    BMY   BAX  AKAM    NaN\n",
       "24   NaN    AME   DLTR    DGX   DOX    ADI    RSG   NaN   SLB    WMB\n",
       "25  CTRA    ADI    STZ   WTRG   NaN   RVTY    NOC   NaN  ALGN    NaN\n",
       "26  HOLX    FDX    LKQ    TMO  SNPS     CF    CRL   NaN  NFLX   NDAQ\n",
       "27   UHS    WST  CMCSA   LDOS   BAX     GE  GOOGL   NaN   CVX    NSC\n",
       "28   KMX    NaN   ISRG    LKQ   HRL     ON   FBIN   NaN  META    DFS\n",
       "29   DVA   HUBB    NaN   CASY  AKAM   MCHP    DOV   NaN   NaN    EPD\n",
       "30   EPD     PH    NaN  CMCSA   LUV  GOOGL    NSC   NaN   HAL    BAX\n",
       "31   STZ   TECH    NaN   SSNC  LAMR    CAT   BLDR   NaN   AMD  CMCSA\n",
       "32  META    UNH    NaN    NaN   NaN    MKC   LDOS   NaN   NaN    NaN\n",
       "33   NaN    NaN    NaN    NaN    EA    SCI    NRG   NaN   NaN   SSNC\n",
       "34   APD    NaN    NaN    NaN   NaN     GM     VZ   NaN   NaN    NaN\n",
       "35  CASY    NaN    NaN    NaN   NaN    NaN    GIS   NaN   NaN    NaN\n",
       "36    WM    NaN    NaN    NaN   NaN     ET    ICE   NaN   NaN    NaN\n",
       "37  ISRG    NaN    NaN    NaN   NaN    IBM   CASY   NaN   NaN    NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c455c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers.to_excel(r\"C:\\Users\\david\\Desktop\\дипломная\\код\\data\\selected_companies.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e33e29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prices.to_excel(r\"C:\\Users\\david\\Desktop\\дипломная\\код\\data\\data_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a18e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаляю в тикерах значения которые не прошли проверку\n",
    "\n",
    "tickers.replace(removed_columns, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8540ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраняю копию чтобы не прогружать все вышенаписанное заново \n",
    "prices_1 = prices.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "00e9f9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2172020849.py:3: FutureWarning: Passing method to DatetimeIndex.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n",
      "  nearest_date_index = date_index.get_loc(target_date, method='nearest')\n"
     ]
    }
   ],
   "source": [
    "#даты ребалансировки \n",
    "data_rebalance = [\n",
    "                 (\"2015-01-10\", \"2015-06-15\"),\n",
    "                 (\"2016-01-10\", \"2016-06-15\"),\n",
    "                 (\"2017-01-10\", \"2017-06-15\"),\n",
    "                 (\"2018-01-10\", \"2018-06-15\"),\n",
    "                 (\"2019-01-10\", \"2019-06-15\"),\n",
    "                 (\"2020-01-10\", \"2020-06-15\"),\n",
    "                 (\"2021-01-10\", \"2021-06-15\"),\n",
    "                 (\"2022-01-10\", \"2022-06-15\"),\n",
    "                 (\"2023-01-10\", \"2023-06-15\")]\n",
    "\n",
    "#обновляю даты на существющие в prices_1\n",
    "new_data_rebalance = []\n",
    "for start_date, end_date in data_rebalance:\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    #получаю ближайшие даты из индекса prices_1\n",
    "    nearest_start_date = get_nearest_date(start_date, prices_1.index)\n",
    "    nearest_end_date = get_nearest_date(end_date, prices_1.index)\n",
    "    #обновляю список\n",
    "    new_data_rebalance.append((nearest_start_date, nearest_end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c64df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df54d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53874408",
   "metadata": {},
   "source": [
    "# Фукнции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2c79af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ДОБАВЛЕНИЕ RSI\n",
    "\n",
    "def calculate_rsi(data, column_name, period=14):\n",
    "    #расчет изм цен\n",
    "    delta = data[column_name].diff()\n",
    "    # Отделяю приросты и падения\n",
    "    gains = (delta.where(delta > 0, 0)).fillna(0)\n",
    "    losses = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "    # считаю экспоненциальное скользящее среднее для приростов и падений\n",
    "    avg_gain = gains.ewm(com=period - 1, min_periods=period).mean()\n",
    "    avg_loss = losses.ewm(com=period - 1, min_periods=period).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9877a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#расчет скользящего СО и корреляции доходности\n",
    "\n",
    "def calculate_rolling_stats(data, columns, main, window=30):\n",
    "    \n",
    "    results = pd.DataFrame(index=data.index)\n",
    "    \n",
    "    # Скользящее стандартное отклонение для каждого столбца\n",
    "    for column in columns:\n",
    "        results[f'{column.split(\"_\")[0]}_rolling_std'] = data[column].rolling(window=window).std()\n",
    "    \n",
    "    # Скользящие корреляции между парами столбцов\n",
    "    for column in columns:\n",
    "        if column == main:\n",
    "            continue    \n",
    "        col_name = f'{main.split(\"_\")[0]}_{column.split(\"_\")[0]}_rolling_corr'\n",
    "        results[col_name] = data[main].rolling(window=window).corr(data[column])\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "fa57c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция для создание окна\n",
    "def create_rolling_windows(data, window_size):\n",
    "    \"\"\"\n",
    "    X (list of np.array): Список окон, где каждое окно содержит данные из 'window_size' последовательных строк.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = []\n",
    "    \n",
    "    for start in range(len(data) - window_size + 1):\n",
    "        end = start + window_size\n",
    "        window = data.iloc[start:end]\n",
    "        X.append(window.values)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ac7fb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_metric(data, threshold=0.5):\n",
    "    # Вычисляем асимметрию\n",
    "    skewness = skew(data)\n",
    "    # Сравниваем абсолютное значение асимметрии с порогом\n",
    "    if abs(skewness) > threshold:\n",
    "        # Асимметрия сильно отличается от нормального распределения\n",
    "        median_value = np.median(data)\n",
    "        #print(\"Асимметрия велика, используем медиану:\", median_value)\n",
    "        return median_value\n",
    "    else:\n",
    "        # Асимметрия близка к нормальному распределению\n",
    "        mean_value = np.mean(data)\n",
    "        #print(\"Асимметрия мала, используем среднее:\", mean_value)\n",
    "        return mean_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "173369ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_date(target_date, date_index):\n",
    "    #нахожу индекс блиашей даты\n",
    "    nearest_date_index = date_index.get_loc(target_date, method='nearest')\n",
    "    return date_index[nearest_date_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5588e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_RSI = [20, 50, 80, 110, 130]\n",
    "roll_return = [10, 20, 40, 60, 80, 100]\n",
    "window_sizes_std_corr = [10, 30, 40, 60, 80, 120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4fb59143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем обьекты для стандартизации наших данных \n",
    "#каждый обеькт предназначен определенной переменной\n",
    "\n",
    "scaler_RSI = StandardScaler()\n",
    "scaler_return = StandardScaler()\n",
    "scaler_std = StandardScaler()\n",
    "scaler_corr = StandardScaler()\n",
    "\n",
    "\n",
    "# создаю обьект для сжатия данных до 2 компонент\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "\n",
    "#создаю обьект NearestNeighbors\n",
    "knn = NearestNeighbors(n_neighbors=300, algorithm='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "54e4fe64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PG</td>\n",
       "      <td>CSX</td>\n",
       "      <td>PG</td>\n",
       "      <td>PG</td>\n",
       "      <td>BDX</td>\n",
       "      <td>IEX</td>\n",
       "      <td>CSL</td>\n",
       "      <td>XYL</td>\n",
       "      <td>ELV</td>\n",
       "      <td>CTSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PGR</td>\n",
       "      <td>TSN</td>\n",
       "      <td>CSL</td>\n",
       "      <td>A</td>\n",
       "      <td>SWK</td>\n",
       "      <td>A</td>\n",
       "      <td>CTSH</td>\n",
       "      <td>CTSH</td>\n",
       "      <td>BIIB</td>\n",
       "      <td>BLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROP</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>A</td>\n",
       "      <td>SCHW</td>\n",
       "      <td>MDLZ</td>\n",
       "      <td>TXRH</td>\n",
       "      <td>IEX</td>\n",
       "      <td>IEX</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>TKO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DG</td>\n",
       "      <td>DRI</td>\n",
       "      <td>SWK</td>\n",
       "      <td>SWK</td>\n",
       "      <td>ELV</td>\n",
       "      <td>TDY</td>\n",
       "      <td>BLK</td>\n",
       "      <td>BLK</td>\n",
       "      <td>DLTR</td>\n",
       "      <td>COP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TDY</td>\n",
       "      <td>EXPE</td>\n",
       "      <td>ENTG</td>\n",
       "      <td>TXRH</td>\n",
       "      <td>ROP</td>\n",
       "      <td>WSO</td>\n",
       "      <td>SWK</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>WMT</td>\n",
       "      <td>DOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SNA</td>\n",
       "      <td>RL</td>\n",
       "      <td>TXRH</td>\n",
       "      <td>EME</td>\n",
       "      <td>DOC</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>DRI</td>\n",
       "      <td>DLTR</td>\n",
       "      <td>AME</td>\n",
       "      <td>EMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TFX</td>\n",
       "      <td>WMT</td>\n",
       "      <td>EXPE</td>\n",
       "      <td>EXPE</td>\n",
       "      <td>AJG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EME</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>CMI</td>\n",
       "      <td>HOLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RVTY</td>\n",
       "      <td>DKS</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>IFF</td>\n",
       "      <td>SNPS</td>\n",
       "      <td>NDAQ</td>\n",
       "      <td>TFX</td>\n",
       "      <td>DHR</td>\n",
       "      <td>SNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNPS</td>\n",
       "      <td>EPD</td>\n",
       "      <td>TFX</td>\n",
       "      <td>ODFL</td>\n",
       "      <td>FIS</td>\n",
       "      <td>APD</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>BSX</td>\n",
       "      <td>ITT</td>\n",
       "      <td>GD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CF</td>\n",
       "      <td>STZ</td>\n",
       "      <td>ODFL</td>\n",
       "      <td>WBA</td>\n",
       "      <td>NDAQ</td>\n",
       "      <td>HRL</td>\n",
       "      <td>CRM</td>\n",
       "      <td>AME</td>\n",
       "      <td>APD</td>\n",
       "      <td>TROW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CTAS</td>\n",
       "      <td>BEN</td>\n",
       "      <td>WBA</td>\n",
       "      <td>ALB</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>CSL</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUM</td>\n",
       "      <td>CBRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>DKS</td>\n",
       "      <td>AME</td>\n",
       "      <td>NSC</td>\n",
       "      <td>ROP</td>\n",
       "      <td>AXP</td>\n",
       "      <td>ITT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CI</td>\n",
       "      <td>JNPR</td>\n",
       "      <td>SNPS</td>\n",
       "      <td>SNPS</td>\n",
       "      <td>TMO</td>\n",
       "      <td>DGX</td>\n",
       "      <td>BRO</td>\n",
       "      <td>APD</td>\n",
       "      <td>NSC</td>\n",
       "      <td>ITT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ON</td>\n",
       "      <td>DHI</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ITT</td>\n",
       "      <td>WMT</td>\n",
       "      <td>AJG</td>\n",
       "      <td>AME</td>\n",
       "      <td>AKAM</td>\n",
       "      <td>LDOS</td>\n",
       "      <td>LYV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SSNC</td>\n",
       "      <td>RCL</td>\n",
       "      <td>GE</td>\n",
       "      <td>BAX</td>\n",
       "      <td>AME</td>\n",
       "      <td>DIS</td>\n",
       "      <td>ADI</td>\n",
       "      <td>JBHT</td>\n",
       "      <td>RPM</td>\n",
       "      <td>HUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CNC</td>\n",
       "      <td>DECK</td>\n",
       "      <td>HUBB</td>\n",
       "      <td>APD</td>\n",
       "      <td>RVTY</td>\n",
       "      <td>NDAQ</td>\n",
       "      <td>DHR</td>\n",
       "      <td>AOS</td>\n",
       "      <td>UTHR</td>\n",
       "      <td>INTU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SAIA</td>\n",
       "      <td>PG</td>\n",
       "      <td>HUM</td>\n",
       "      <td>HRL</td>\n",
       "      <td>HAL</td>\n",
       "      <td>DLTR</td>\n",
       "      <td>PCAR</td>\n",
       "      <td>CBRE</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ET</td>\n",
       "      <td>IEX</td>\n",
       "      <td>PH</td>\n",
       "      <td>HUBB</td>\n",
       "      <td>DECK</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>CBRE</td>\n",
       "      <td>SAIA</td>\n",
       "      <td>SPGI</td>\n",
       "      <td>WSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CSX</td>\n",
       "      <td>ROP</td>\n",
       "      <td>AKAM</td>\n",
       "      <td>HUM</td>\n",
       "      <td>IEX</td>\n",
       "      <td>TMO</td>\n",
       "      <td>PKG</td>\n",
       "      <td>EA</td>\n",
       "      <td>TFX</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DRI</td>\n",
       "      <td>TXRH</td>\n",
       "      <td>CSX</td>\n",
       "      <td>AKAM</td>\n",
       "      <td>A</td>\n",
       "      <td>WMT</td>\n",
       "      <td>APD</td>\n",
       "      <td>MKC</td>\n",
       "      <td>GD</td>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CAT</td>\n",
       "      <td>AZPN</td>\n",
       "      <td>XYL</td>\n",
       "      <td>TECH</td>\n",
       "      <td>TXRH</td>\n",
       "      <td>BSX</td>\n",
       "      <td>HRL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TROW</td>\n",
       "      <td>SNPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WTRG</td>\n",
       "      <td>HEI</td>\n",
       "      <td>SCHW</td>\n",
       "      <td>TKO</td>\n",
       "      <td>EXPE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PWR</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ALGN</td>\n",
       "      <td>DIS</td>\n",
       "      <td>WTRG</td>\n",
       "      <td>ISRG</td>\n",
       "      <td>WSO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSX</td>\n",
       "      <td>NSC</td>\n",
       "      <td>WRB</td>\n",
       "      <td>MKC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>IP</td>\n",
       "      <td>ANSS</td>\n",
       "      <td>SCCO</td>\n",
       "      <td>CNP</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>AME</td>\n",
       "      <td>BMY</td>\n",
       "      <td>BAX</td>\n",
       "      <td>AKAM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AME</td>\n",
       "      <td>DLTR</td>\n",
       "      <td>DGX</td>\n",
       "      <td>DOX</td>\n",
       "      <td>ADI</td>\n",
       "      <td>RSG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SLB</td>\n",
       "      <td>WMB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CTRA</td>\n",
       "      <td>ADI</td>\n",
       "      <td>STZ</td>\n",
       "      <td>WTRG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RVTY</td>\n",
       "      <td>NOC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALGN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HOLX</td>\n",
       "      <td>FDX</td>\n",
       "      <td>LKQ</td>\n",
       "      <td>TMO</td>\n",
       "      <td>SNPS</td>\n",
       "      <td>CF</td>\n",
       "      <td>CRL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>NDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>UHS</td>\n",
       "      <td>WST</td>\n",
       "      <td>CMCSA</td>\n",
       "      <td>LDOS</td>\n",
       "      <td>BAX</td>\n",
       "      <td>GE</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CVX</td>\n",
       "      <td>NSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KMX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISRG</td>\n",
       "      <td>LKQ</td>\n",
       "      <td>HRL</td>\n",
       "      <td>ON</td>\n",
       "      <td>FBIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>META</td>\n",
       "      <td>DFS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DVA</td>\n",
       "      <td>HUBB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASY</td>\n",
       "      <td>AKAM</td>\n",
       "      <td>MCHP</td>\n",
       "      <td>DOV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>EPD</td>\n",
       "      <td>PH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CMCSA</td>\n",
       "      <td>LUV</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>NSC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAL</td>\n",
       "      <td>BAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>STZ</td>\n",
       "      <td>TECH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SSNC</td>\n",
       "      <td>LAMR</td>\n",
       "      <td>CAT</td>\n",
       "      <td>BLDR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMD</td>\n",
       "      <td>CMCSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>META</td>\n",
       "      <td>UNH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MKC</td>\n",
       "      <td>LDOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EA</td>\n",
       "      <td>SCI</td>\n",
       "      <td>NRG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SSNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>APD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GM</td>\n",
       "      <td>VZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CASY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>WM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ET</td>\n",
       "      <td>ICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ISRG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IBM</td>\n",
       "      <td>CASY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    2014   2015   2016   2017  2018   2019   2020  2021  2022   2023\n",
       "0     PG    CSX     PG     PG   BDX    IEX    CSL   XYL   ELV   CTSH\n",
       "1    PGR    TSN    CSL      A   SWK      A   CTSH  CTSH  BIIB    BLK\n",
       "2    ROP  GOOGL      A   SCHW  MDLZ   TXRH    IEX   IEX  CBOE    TKO\n",
       "3     DG    DRI    SWK    SWK   ELV    TDY    BLK   BLK  DLTR    COP\n",
       "4    TDY   EXPE   ENTG   TXRH   ROP    WSO    SWK  CBOE   WMT    DOX\n",
       "5    SNA     RL   TXRH    EME   DOC   CBOE    DRI  DLTR   AME    EMR\n",
       "6    TFX    WMT   EXPE   EXPE   AJG    NaN    EME  TRMB   CMI   HOLX\n",
       "7   RVTY    DKS   TRMB   TRMB   IFF   SNPS   NDAQ   TFX   DHR    SNA\n",
       "8   SNPS    EPD    TFX   ODFL   FIS    APD   CBOE   BSX   ITT     GD\n",
       "9     CF    STZ   ODFL    WBA  NDAQ    HRL    CRM   AME   APD   TROW\n",
       "10  CTAS    BEN    WBA    ALB  TRMB    CSL   TRMB   NaN   HUM   CBRE\n",
       "11  LRCX   NVDA    DKS    AME   NSC    ROP    AXP   ITT   NaN      J\n",
       "12    CI   JNPR   SNPS   SNPS   TMO    DGX    BRO   APD   NSC    ITT\n",
       "13    ON    DHI    ABT    ITT   WMT    AJG    AME  AKAM  LDOS    LYV\n",
       "14  SSNC    RCL     GE    BAX   AME    DIS    ADI  JBHT   RPM    HUM\n",
       "15   CNC   DECK   HUBB    APD  RVTY   NDAQ    DHR   AOS  UTHR   INTU\n",
       "16  SAIA     PG    HUM    HRL   HAL   DLTR   PCAR  CBRE  TRMB  GOOGL\n",
       "17    ET    IEX     PH   HUBB  DECK   TRMB   CBRE  SAIA  SPGI    WSO\n",
       "18   CSX    ROP   AKAM    HUM   IEX    TMO    PKG    EA   TFX   NFLX\n",
       "19   DRI   TXRH    CSX   AKAM     A    WMT    APD   MKC    GD   META\n",
       "20   CAT   AZPN    XYL   TECH  TXRH    BSX    HRL   NaN  TROW   SNPS\n",
       "21  WTRG    HEI   SCHW    TKO  EXPE    NaN   SAIA   NaN   PWR    CAG\n",
       "22  ALGN    DIS   WTRG   ISRG   WSO    NaN    CSX   NSC   WRB    MKC\n",
       "23    IP   ANSS   SCCO    CNP  CBOE    AME    BMY   BAX  AKAM    NaN\n",
       "24   NaN    AME   DLTR    DGX   DOX    ADI    RSG   NaN   SLB    WMB\n",
       "25  CTRA    ADI    STZ   WTRG   NaN   RVTY    NOC   NaN  ALGN    NaN\n",
       "26  HOLX    FDX    LKQ    TMO  SNPS     CF    CRL   NaN  NFLX   NDAQ\n",
       "27   UHS    WST  CMCSA   LDOS   BAX     GE  GOOGL   NaN   CVX    NSC\n",
       "28   KMX    NaN   ISRG    LKQ   HRL     ON   FBIN   NaN  META    DFS\n",
       "29   DVA   HUBB    NaN   CASY  AKAM   MCHP    DOV   NaN   NaN    EPD\n",
       "30   EPD     PH    NaN  CMCSA   LUV  GOOGL    NSC   NaN   HAL    BAX\n",
       "31   STZ   TECH    NaN   SSNC  LAMR    CAT   BLDR   NaN   AMD  CMCSA\n",
       "32  META    UNH    NaN    NaN   NaN    MKC   LDOS   NaN   NaN    NaN\n",
       "33   NaN    NaN    NaN    NaN    EA    SCI    NRG   NaN   NaN   SSNC\n",
       "34   APD    NaN    NaN    NaN   NaN     GM     VZ   NaN   NaN    NaN\n",
       "35  CASY    NaN    NaN    NaN   NaN    NaN    GIS   NaN   NaN    NaN\n",
       "36    WM    NaN    NaN    NaN   NaN     ET    ICE   NaN   NaN    NaN\n",
       "37  ISRG    NaN    NaN    NaN   NaN    IBM   CASY   NaN   NaN    NaN"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cde197a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_name = \"PG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e9e83a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#оттбираю компании которые демонтсрируют \"сильную\" корреляцию\n",
    "indicators_factors = []\n",
    "\n",
    "for i in prices_1.columns.tolist()[:-3]:\n",
    "    if prices_1[main_name].corr(prices_1[i]) > 0.6 or prices_1[main_name].corr(prices_1[i]) < 0.6:\n",
    "        indicators_factors.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7de0f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#выбираю случайно индикатоыр команий\n",
    "if len(indicators_factors) < 25:\n",
    "    indicators_sample = random.sample(indicators_factors, len(indicators_factors))\n",
    "else:\n",
    "    indicators_sample = random.sample(indicators_factors, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "108b9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#проверка наличия рассматриваемой бумаги в списке \n",
    "if main_name not in indicators_sample:\n",
    "    indicators_sample.append(main_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "62668b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#добавляю голд и нефть и голд\n",
    "for i in prices_1.columns[-3:].tolist():\n",
    "    if i in indicators_sample:\n",
    "        continue\n",
    "    else:\n",
    "        indicators_sample.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "714097dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indicators_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "291e635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#беру котировки отобранных компаний\n",
    "data_selected = prices_1[indicators_sample]\n",
    "data_selected_1 = data_selected.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9f1ad074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VRSK</th>\n",
       "      <th>JNPR</th>\n",
       "      <th>IT</th>\n",
       "      <th>CCI</th>\n",
       "      <th>KO</th>\n",
       "      <th>PG</th>\n",
       "      <th>DFS</th>\n",
       "      <th>GIS</th>\n",
       "      <th>RMD</th>\n",
       "      <th>DKS</th>\n",
       "      <th>...</th>\n",
       "      <th>QCOM</th>\n",
       "      <th>BEN</th>\n",
       "      <th>SRE</th>\n",
       "      <th>PTC</th>\n",
       "      <th>CPB</th>\n",
       "      <th>TXRH</th>\n",
       "      <th>FBIN</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Gold</th>\n",
       "      <th>SP_500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-05-18</th>\n",
       "      <td>47.939999</td>\n",
       "      <td>17.340000</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>53.200001</td>\n",
       "      <td>37.625000</td>\n",
       "      <td>64.190002</td>\n",
       "      <td>31.700001</td>\n",
       "      <td>39.340000</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>45.330002</td>\n",
       "      <td>...</td>\n",
       "      <td>57.459999</td>\n",
       "      <td>36.256668</td>\n",
       "      <td>31.985001</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>33.910000</td>\n",
       "      <td>17.309999</td>\n",
       "      <td>18.615385</td>\n",
       "      <td>107.139999</td>\n",
       "      <td>1591.599976</td>\n",
       "      <td>1295.219971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-21</th>\n",
       "      <td>47.669998</td>\n",
       "      <td>17.410000</td>\n",
       "      <td>41.230000</td>\n",
       "      <td>53.029999</td>\n",
       "      <td>37.105000</td>\n",
       "      <td>63.660000</td>\n",
       "      <td>31.520000</td>\n",
       "      <td>38.990002</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>46.529999</td>\n",
       "      <td>...</td>\n",
       "      <td>55.849998</td>\n",
       "      <td>35.943333</td>\n",
       "      <td>31.924999</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>33.119999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>18.897436</td>\n",
       "      <td>108.809998</td>\n",
       "      <td>1588.400024</td>\n",
       "      <td>1315.989990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-22</th>\n",
       "      <td>47.900002</td>\n",
       "      <td>17.990000</td>\n",
       "      <td>41.650002</td>\n",
       "      <td>53.480000</td>\n",
       "      <td>37.290001</td>\n",
       "      <td>63.430000</td>\n",
       "      <td>32.790001</td>\n",
       "      <td>38.549999</td>\n",
       "      <td>32.259998</td>\n",
       "      <td>46.310001</td>\n",
       "      <td>...</td>\n",
       "      <td>57.410000</td>\n",
       "      <td>36.320000</td>\n",
       "      <td>32.070000</td>\n",
       "      <td>20.860001</td>\n",
       "      <td>32.799999</td>\n",
       "      <td>17.830000</td>\n",
       "      <td>18.846153</td>\n",
       "      <td>108.410004</td>\n",
       "      <td>1576.300049</td>\n",
       "      <td>1316.630005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-23</th>\n",
       "      <td>47.810001</td>\n",
       "      <td>17.629999</td>\n",
       "      <td>41.770000</td>\n",
       "      <td>53.070000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>31.990000</td>\n",
       "      <td>38.560001</td>\n",
       "      <td>31.959999</td>\n",
       "      <td>47.310001</td>\n",
       "      <td>...</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>35.700001</td>\n",
       "      <td>31.920000</td>\n",
       "      <td>20.670000</td>\n",
       "      <td>32.520000</td>\n",
       "      <td>17.990000</td>\n",
       "      <td>18.803419</td>\n",
       "      <td>105.559998</td>\n",
       "      <td>1548.099976</td>\n",
       "      <td>1318.859985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-24</th>\n",
       "      <td>48.200001</td>\n",
       "      <td>17.270000</td>\n",
       "      <td>41.639999</td>\n",
       "      <td>53.830002</td>\n",
       "      <td>37.395000</td>\n",
       "      <td>62.490002</td>\n",
       "      <td>32.570000</td>\n",
       "      <td>38.709999</td>\n",
       "      <td>32.099998</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.410000</td>\n",
       "      <td>36.153332</td>\n",
       "      <td>31.785000</td>\n",
       "      <td>20.410000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>18.070000</td>\n",
       "      <td>19.111111</td>\n",
       "      <td>106.550003</td>\n",
       "      <td>1557.300049</td>\n",
       "      <td>1320.680054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>241.229996</td>\n",
       "      <td>37.430000</td>\n",
       "      <td>468.760010</td>\n",
       "      <td>108.410004</td>\n",
       "      <td>59.759998</td>\n",
       "      <td>146.970001</td>\n",
       "      <td>97.750000</td>\n",
       "      <td>63.029999</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>152.270004</td>\n",
       "      <td>...</td>\n",
       "      <td>152.750000</td>\n",
       "      <td>28.090000</td>\n",
       "      <td>72.910004</td>\n",
       "      <td>176.990005</td>\n",
       "      <td>43.099998</td>\n",
       "      <td>121.440002</td>\n",
       "      <td>79.459999</td>\n",
       "      <td>80.059998</td>\n",
       "      <td>2019.800049</td>\n",
       "      <td>4850.430176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>243.009995</td>\n",
       "      <td>37.410000</td>\n",
       "      <td>469.160004</td>\n",
       "      <td>109.010002</td>\n",
       "      <td>59.529999</td>\n",
       "      <td>153.110001</td>\n",
       "      <td>99.769997</td>\n",
       "      <td>63.389999</td>\n",
       "      <td>177.320007</td>\n",
       "      <td>150.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>152.869995</td>\n",
       "      <td>28.420000</td>\n",
       "      <td>71.720001</td>\n",
       "      <td>177.919998</td>\n",
       "      <td>43.119999</td>\n",
       "      <td>121.790001</td>\n",
       "      <td>76.860001</td>\n",
       "      <td>79.550003</td>\n",
       "      <td>2023.699951</td>\n",
       "      <td>4864.600098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>245.000000</td>\n",
       "      <td>37.430000</td>\n",
       "      <td>470.970001</td>\n",
       "      <td>108.480003</td>\n",
       "      <td>59.799999</td>\n",
       "      <td>153.929993</td>\n",
       "      <td>100.879997</td>\n",
       "      <td>64.650002</td>\n",
       "      <td>175.470001</td>\n",
       "      <td>150.789993</td>\n",
       "      <td>...</td>\n",
       "      <td>154.789993</td>\n",
       "      <td>27.580000</td>\n",
       "      <td>72.220001</td>\n",
       "      <td>179.779999</td>\n",
       "      <td>44.209999</td>\n",
       "      <td>122.739998</td>\n",
       "      <td>75.900002</td>\n",
       "      <td>80.040001</td>\n",
       "      <td>2013.900024</td>\n",
       "      <td>4868.549805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>244.580002</td>\n",
       "      <td>37.330002</td>\n",
       "      <td>466.679993</td>\n",
       "      <td>108.970001</td>\n",
       "      <td>59.009998</td>\n",
       "      <td>152.399994</td>\n",
       "      <td>101.709999</td>\n",
       "      <td>63.860001</td>\n",
       "      <td>189.559998</td>\n",
       "      <td>153.149994</td>\n",
       "      <td>...</td>\n",
       "      <td>157.600006</td>\n",
       "      <td>27.129999</td>\n",
       "      <td>70.430000</td>\n",
       "      <td>180.529999</td>\n",
       "      <td>44.139999</td>\n",
       "      <td>122.970001</td>\n",
       "      <td>78.830002</td>\n",
       "      <td>82.430000</td>\n",
       "      <td>2016.900024</td>\n",
       "      <td>4894.160156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>244.389999</td>\n",
       "      <td>37.220001</td>\n",
       "      <td>459.709991</td>\n",
       "      <td>110.769997</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>155.809998</td>\n",
       "      <td>104.239998</td>\n",
       "      <td>64.779999</td>\n",
       "      <td>187.979996</td>\n",
       "      <td>153.029999</td>\n",
       "      <td>...</td>\n",
       "      <td>152.210007</td>\n",
       "      <td>27.520000</td>\n",
       "      <td>70.860001</td>\n",
       "      <td>180.029999</td>\n",
       "      <td>44.400002</td>\n",
       "      <td>122.820000</td>\n",
       "      <td>79.150002</td>\n",
       "      <td>83.550003</td>\n",
       "      <td>2016.800049</td>\n",
       "      <td>4890.970215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2915 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  VRSK       JNPR          IT         CCI         KO  \\\n",
       "Date                                                                   \n",
       "2012-05-18   47.939999  17.340000   42.119999   53.200001  37.625000   \n",
       "2012-05-21   47.669998  17.410000   41.230000   53.029999  37.105000   \n",
       "2012-05-22   47.900002  17.990000   41.650002   53.480000  37.290001   \n",
       "2012-05-23   47.810001  17.629999   41.770000   53.070000  37.000000   \n",
       "2012-05-24   48.200001  17.270000   41.639999   53.830002  37.395000   \n",
       "...                ...        ...         ...         ...        ...   \n",
       "2024-01-22  241.229996  37.430000  468.760010  108.410004  59.759998   \n",
       "2024-01-23  243.009995  37.410000  469.160004  109.010002  59.529999   \n",
       "2024-01-24  245.000000  37.430000  470.970001  108.480003  59.799999   \n",
       "2024-01-25  244.580002  37.330002  466.679993  108.970001  59.009998   \n",
       "2024-01-26  244.389999  37.220001  459.709991  110.769997  59.250000   \n",
       "\n",
       "                    PG         DFS        GIS         RMD         DKS  ...  \\\n",
       "Date                                                                   ...   \n",
       "2012-05-18   64.190002   31.700001  39.340000   32.250000   45.330002  ...   \n",
       "2012-05-21   63.660000   31.520000  38.990002   31.750000   46.529999  ...   \n",
       "2012-05-22   63.430000   32.790001  38.549999   32.259998   46.310001  ...   \n",
       "2012-05-23   63.000000   31.990000  38.560001   31.959999   47.310001  ...   \n",
       "2012-05-24   62.490002   32.570000  38.709999   32.099998   47.500000  ...   \n",
       "...                ...         ...        ...         ...         ...  ...   \n",
       "2024-01-22  146.970001   97.750000  63.029999  174.000000  152.270004  ...   \n",
       "2024-01-23  153.110001   99.769997  63.389999  177.320007  150.250000  ...   \n",
       "2024-01-24  153.929993  100.879997  64.650002  175.470001  150.789993  ...   \n",
       "2024-01-25  152.399994  101.709999  63.860001  189.559998  153.149994  ...   \n",
       "2024-01-26  155.809998  104.239998  64.779999  187.979996  153.029999  ...   \n",
       "\n",
       "                  QCOM        BEN        SRE         PTC        CPB  \\\n",
       "Date                                                                  \n",
       "2012-05-18   57.459999  36.256668  31.985001   20.000000  33.910000   \n",
       "2012-05-21   55.849998  35.943333  31.924999   20.010000  33.119999   \n",
       "2012-05-22   57.410000  36.320000  32.070000   20.860001  32.799999   \n",
       "2012-05-23   57.500000  35.700001  31.920000   20.670000  32.520000   \n",
       "2012-05-24   58.410000  36.153332  31.785000   20.410000  32.500000   \n",
       "...                ...        ...        ...         ...        ...   \n",
       "2024-01-22  152.750000  28.090000  72.910004  176.990005  43.099998   \n",
       "2024-01-23  152.869995  28.420000  71.720001  177.919998  43.119999   \n",
       "2024-01-24  154.789993  27.580000  72.220001  179.779999  44.209999   \n",
       "2024-01-25  157.600006  27.129999  70.430000  180.529999  44.139999   \n",
       "2024-01-26  152.210007  27.520000  70.860001  180.029999  44.400002   \n",
       "\n",
       "                  TXRH       FBIN       Brent         Gold       SP_500  \n",
       "Date                                                                     \n",
       "2012-05-18   17.309999  18.615385  107.139999  1591.599976  1295.219971  \n",
       "2012-05-21   17.719999  18.897436  108.809998  1588.400024  1315.989990  \n",
       "2012-05-22   17.830000  18.846153  108.410004  1576.300049  1316.630005  \n",
       "2012-05-23   17.990000  18.803419  105.559998  1548.099976  1318.859985  \n",
       "2012-05-24   18.070000  19.111111  106.550003  1557.300049  1320.680054  \n",
       "...                ...        ...         ...          ...          ...  \n",
       "2024-01-22  121.440002  79.459999   80.059998  2019.800049  4850.430176  \n",
       "2024-01-23  121.790001  76.860001   79.550003  2023.699951  4864.600098  \n",
       "2024-01-24  122.739998  75.900002   80.040001  2013.900024  4868.549805  \n",
       "2024-01-25  122.970001  78.830002   82.430000  2016.900024  4894.160156  \n",
       "2024-01-26  122.820000  79.150002   83.550003  2016.800049  4890.970215  \n",
       "\n",
       "[2915 rows x 28 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3f469202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление признаков "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "901ddc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[new_column_name] = rsi_series\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\3560832728.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#добавляю RSI С РАЗНЫМИ ЛАГАМИ\n",
    "for column_RSI in data_selected_1.columns:\n",
    "    for period_rsi in roll_RSI:\n",
    "        rsi_series = calculate_rsi(data_selected, column_RSI, period_rsi)\n",
    "        new_column_name = f'{column_RSI}_RSI_{period_rsi}'\n",
    "        data_selected[new_column_name] = rsi_series\n",
    "        \n",
    "#УДАЛЯЕМ ПРОПУСКИ\n",
    "data_selected.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "51fe209e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VRSK</th>\n",
       "      <th>JNPR</th>\n",
       "      <th>IT</th>\n",
       "      <th>CCI</th>\n",
       "      <th>KO</th>\n",
       "      <th>PG</th>\n",
       "      <th>DFS</th>\n",
       "      <th>GIS</th>\n",
       "      <th>RMD</th>\n",
       "      <th>DKS</th>\n",
       "      <th>...</th>\n",
       "      <th>Gold_RSI_20</th>\n",
       "      <th>Gold_RSI_50</th>\n",
       "      <th>Gold_RSI_80</th>\n",
       "      <th>Gold_RSI_110</th>\n",
       "      <th>Gold_RSI_130</th>\n",
       "      <th>SP_500_RSI_20</th>\n",
       "      <th>SP_500_RSI_50</th>\n",
       "      <th>SP_500_RSI_80</th>\n",
       "      <th>SP_500_RSI_110</th>\n",
       "      <th>SP_500_RSI_130</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-11-30</th>\n",
       "      <td>49.400002</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>47.869999</td>\n",
       "      <td>67.419998</td>\n",
       "      <td>37.939999</td>\n",
       "      <td>69.370003</td>\n",
       "      <td>41.529999</td>\n",
       "      <td>40.820000</td>\n",
       "      <td>41.259998</td>\n",
       "      <td>52.509998</td>\n",
       "      <td>...</td>\n",
       "      <td>46.941190</td>\n",
       "      <td>51.687813</td>\n",
       "      <td>52.869428</td>\n",
       "      <td>53.297812</td>\n",
       "      <td>53.447104</td>\n",
       "      <td>52.587842</td>\n",
       "      <td>52.494845</td>\n",
       "      <td>53.418164</td>\n",
       "      <td>53.929501</td>\n",
       "      <td>54.149117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-03</th>\n",
       "      <td>49.790001</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>47.619999</td>\n",
       "      <td>67.849998</td>\n",
       "      <td>37.900002</td>\n",
       "      <td>69.839996</td>\n",
       "      <td>41.810001</td>\n",
       "      <td>41.029999</td>\n",
       "      <td>41.240002</td>\n",
       "      <td>52.480000</td>\n",
       "      <td>...</td>\n",
       "      <td>48.958489</td>\n",
       "      <td>52.497004</td>\n",
       "      <td>53.433738</td>\n",
       "      <td>53.765807</td>\n",
       "      <td>53.878615</td>\n",
       "      <td>50.520096</td>\n",
       "      <td>51.588414</td>\n",
       "      <td>52.757118</td>\n",
       "      <td>53.370362</td>\n",
       "      <td>53.629603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-04</th>\n",
       "      <td>49.990002</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>47.139999</td>\n",
       "      <td>67.669998</td>\n",
       "      <td>37.310001</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>41.209999</td>\n",
       "      <td>40.580002</td>\n",
       "      <td>40.759998</td>\n",
       "      <td>51.910000</td>\n",
       "      <td>...</td>\n",
       "      <td>43.872615</td>\n",
       "      <td>50.020718</td>\n",
       "      <td>51.620789</td>\n",
       "      <td>52.235704</td>\n",
       "      <td>52.459217</td>\n",
       "      <td>49.781206</td>\n",
       "      <td>51.264497</td>\n",
       "      <td>52.521089</td>\n",
       "      <td>53.170855</td>\n",
       "      <td>53.444299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-05</th>\n",
       "      <td>48.590000</td>\n",
       "      <td>17.980000</td>\n",
       "      <td>46.349998</td>\n",
       "      <td>67.190002</td>\n",
       "      <td>37.200001</td>\n",
       "      <td>69.480003</td>\n",
       "      <td>41.150002</td>\n",
       "      <td>40.689999</td>\n",
       "      <td>40.939999</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>43.495143</td>\n",
       "      <td>49.830363</td>\n",
       "      <td>51.480409</td>\n",
       "      <td>52.116911</td>\n",
       "      <td>52.348917</td>\n",
       "      <td>50.486573</td>\n",
       "      <td>51.551730</td>\n",
       "      <td>52.719301</td>\n",
       "      <td>53.333757</td>\n",
       "      <td>53.593823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-06</th>\n",
       "      <td>49.040001</td>\n",
       "      <td>18.270000</td>\n",
       "      <td>46.520000</td>\n",
       "      <td>66.970001</td>\n",
       "      <td>37.340000</td>\n",
       "      <td>69.480003</td>\n",
       "      <td>40.869999</td>\n",
       "      <td>41.029999</td>\n",
       "      <td>40.840000</td>\n",
       "      <td>51.130001</td>\n",
       "      <td>...</td>\n",
       "      <td>45.446727</td>\n",
       "      <td>50.588272</td>\n",
       "      <td>52.002517</td>\n",
       "      <td>52.547091</td>\n",
       "      <td>52.744431</td>\n",
       "      <td>51.970490</td>\n",
       "      <td>52.153034</td>\n",
       "      <td>53.133333</td>\n",
       "      <td>53.673604</td>\n",
       "      <td>53.905580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>241.229996</td>\n",
       "      <td>37.430000</td>\n",
       "      <td>468.760010</td>\n",
       "      <td>108.410004</td>\n",
       "      <td>59.759998</td>\n",
       "      <td>146.970001</td>\n",
       "      <td>97.750000</td>\n",
       "      <td>63.029999</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>152.270004</td>\n",
       "      <td>...</td>\n",
       "      <td>49.864197</td>\n",
       "      <td>52.583620</td>\n",
       "      <td>52.747858</td>\n",
       "      <td>52.665655</td>\n",
       "      <td>52.578351</td>\n",
       "      <td>67.457007</td>\n",
       "      <td>62.091152</td>\n",
       "      <td>59.200539</td>\n",
       "      <td>57.362237</td>\n",
       "      <td>56.467181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>243.009995</td>\n",
       "      <td>37.410000</td>\n",
       "      <td>469.160004</td>\n",
       "      <td>109.010002</td>\n",
       "      <td>59.529999</td>\n",
       "      <td>153.110001</td>\n",
       "      <td>99.769997</td>\n",
       "      <td>63.389999</td>\n",
       "      <td>177.320007</td>\n",
       "      <td>150.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.647142</td>\n",
       "      <td>52.887177</td>\n",
       "      <td>52.940196</td>\n",
       "      <td>52.805997</td>\n",
       "      <td>52.697055</td>\n",
       "      <td>68.429799</td>\n",
       "      <td>62.521861</td>\n",
       "      <td>59.476943</td>\n",
       "      <td>57.561978</td>\n",
       "      <td>56.634541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>245.000000</td>\n",
       "      <td>37.430000</td>\n",
       "      <td>470.970001</td>\n",
       "      <td>108.480003</td>\n",
       "      <td>59.799999</td>\n",
       "      <td>153.929993</td>\n",
       "      <td>100.879997</td>\n",
       "      <td>64.650002</td>\n",
       "      <td>175.470001</td>\n",
       "      <td>150.789993</td>\n",
       "      <td>...</td>\n",
       "      <td>48.638028</td>\n",
       "      <td>52.033028</td>\n",
       "      <td>52.397464</td>\n",
       "      <td>52.411925</td>\n",
       "      <td>52.365121</td>\n",
       "      <td>68.704285</td>\n",
       "      <td>62.642584</td>\n",
       "      <td>59.554287</td>\n",
       "      <td>57.617828</td>\n",
       "      <td>56.681321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>244.580002</td>\n",
       "      <td>37.330002</td>\n",
       "      <td>466.679993</td>\n",
       "      <td>108.970001</td>\n",
       "      <td>59.009998</td>\n",
       "      <td>152.399994</td>\n",
       "      <td>101.709999</td>\n",
       "      <td>63.860001</td>\n",
       "      <td>189.559998</td>\n",
       "      <td>153.149994</td>\n",
       "      <td>...</td>\n",
       "      <td>49.286289</td>\n",
       "      <td>52.273804</td>\n",
       "      <td>52.548268</td>\n",
       "      <td>52.521385</td>\n",
       "      <td>52.457505</td>\n",
       "      <td>70.457435</td>\n",
       "      <td>63.422154</td>\n",
       "      <td>60.054894</td>\n",
       "      <td>57.979689</td>\n",
       "      <td>56.984533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>244.389999</td>\n",
       "      <td>37.220001</td>\n",
       "      <td>459.709991</td>\n",
       "      <td>110.769997</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>155.809998</td>\n",
       "      <td>104.239998</td>\n",
       "      <td>64.779999</td>\n",
       "      <td>187.979996</td>\n",
       "      <td>153.029999</td>\n",
       "      <td>...</td>\n",
       "      <td>49.264477</td>\n",
       "      <td>52.264882</td>\n",
       "      <td>52.542651</td>\n",
       "      <td>52.517322</td>\n",
       "      <td>52.454089</td>\n",
       "      <td>69.943715</td>\n",
       "      <td>63.254386</td>\n",
       "      <td>59.961284</td>\n",
       "      <td>57.917530</td>\n",
       "      <td>56.934510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2786 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  VRSK       JNPR          IT         CCI         KO  \\\n",
       "Date                                                                   \n",
       "2012-11-30   49.400002  18.000000   47.869999   67.419998  37.939999   \n",
       "2012-12-03   49.790001  18.100000   47.619999   67.849998  37.900002   \n",
       "2012-12-04   49.990002  18.100000   47.139999   67.669998  37.310001   \n",
       "2012-12-05   48.590000  17.980000   46.349998   67.190002  37.200001   \n",
       "2012-12-06   49.040001  18.270000   46.520000   66.970001  37.340000   \n",
       "...                ...        ...         ...         ...        ...   \n",
       "2024-01-22  241.229996  37.430000  468.760010  108.410004  59.759998   \n",
       "2024-01-23  243.009995  37.410000  469.160004  109.010002  59.529999   \n",
       "2024-01-24  245.000000  37.430000  470.970001  108.480003  59.799999   \n",
       "2024-01-25  244.580002  37.330002  466.679993  108.970001  59.009998   \n",
       "2024-01-26  244.389999  37.220001  459.709991  110.769997  59.250000   \n",
       "\n",
       "                    PG         DFS        GIS         RMD         DKS  ...  \\\n",
       "Date                                                                   ...   \n",
       "2012-11-30   69.370003   41.529999  40.820000   41.259998   52.509998  ...   \n",
       "2012-12-03   69.839996   41.810001  41.029999   41.240002   52.480000  ...   \n",
       "2012-12-04   69.500000   41.209999  40.580002   40.759998   51.910000  ...   \n",
       "2012-12-05   69.480003   41.150002  40.689999   40.939999   51.000000  ...   \n",
       "2012-12-06   69.480003   40.869999  41.029999   40.840000   51.130001  ...   \n",
       "...                ...         ...        ...         ...         ...  ...   \n",
       "2024-01-22  146.970001   97.750000  63.029999  174.000000  152.270004  ...   \n",
       "2024-01-23  153.110001   99.769997  63.389999  177.320007  150.250000  ...   \n",
       "2024-01-24  153.929993  100.879997  64.650002  175.470001  150.789993  ...   \n",
       "2024-01-25  152.399994  101.709999  63.860001  189.559998  153.149994  ...   \n",
       "2024-01-26  155.809998  104.239998  64.779999  187.979996  153.029999  ...   \n",
       "\n",
       "            Gold_RSI_20  Gold_RSI_50  Gold_RSI_80  Gold_RSI_110  Gold_RSI_130  \\\n",
       "Date                                                                            \n",
       "2012-11-30    46.941190    51.687813    52.869428     53.297812     53.447104   \n",
       "2012-12-03    48.958489    52.497004    53.433738     53.765807     53.878615   \n",
       "2012-12-04    43.872615    50.020718    51.620789     52.235704     52.459217   \n",
       "2012-12-05    43.495143    49.830363    51.480409     52.116911     52.348917   \n",
       "2012-12-06    45.446727    50.588272    52.002517     52.547091     52.744431   \n",
       "...                 ...          ...          ...           ...           ...   \n",
       "2024-01-22    49.864197    52.583620    52.747858     52.665655     52.578351   \n",
       "2024-01-23    50.647142    52.887177    52.940196     52.805997     52.697055   \n",
       "2024-01-24    48.638028    52.033028    52.397464     52.411925     52.365121   \n",
       "2024-01-25    49.286289    52.273804    52.548268     52.521385     52.457505   \n",
       "2024-01-26    49.264477    52.264882    52.542651     52.517322     52.454089   \n",
       "\n",
       "            SP_500_RSI_20  SP_500_RSI_50  SP_500_RSI_80  SP_500_RSI_110  \\\n",
       "Date                                                                      \n",
       "2012-11-30      52.587842      52.494845      53.418164       53.929501   \n",
       "2012-12-03      50.520096      51.588414      52.757118       53.370362   \n",
       "2012-12-04      49.781206      51.264497      52.521089       53.170855   \n",
       "2012-12-05      50.486573      51.551730      52.719301       53.333757   \n",
       "2012-12-06      51.970490      52.153034      53.133333       53.673604   \n",
       "...                   ...            ...            ...             ...   \n",
       "2024-01-22      67.457007      62.091152      59.200539       57.362237   \n",
       "2024-01-23      68.429799      62.521861      59.476943       57.561978   \n",
       "2024-01-24      68.704285      62.642584      59.554287       57.617828   \n",
       "2024-01-25      70.457435      63.422154      60.054894       57.979689   \n",
       "2024-01-26      69.943715      63.254386      59.961284       57.917530   \n",
       "\n",
       "            SP_500_RSI_130  \n",
       "Date                        \n",
       "2012-11-30       54.149117  \n",
       "2012-12-03       53.629603  \n",
       "2012-12-04       53.444299  \n",
       "2012-12-05       53.593823  \n",
       "2012-12-06       53.905580  \n",
       "...                    ...  \n",
       "2024-01-22       56.467181  \n",
       "2024-01-23       56.634541  \n",
       "2024-01-24       56.681321  \n",
       "2024-01-25       56.984533  \n",
       "2024-01-26       56.934510  \n",
       "\n",
       "[2786 rows x 168 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5002f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a8ed63ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#пример использвоания \n",
    "\"DG\".endswith('_RSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c2b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c6d1b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#РАСЧЕТ ДОХОДНОСТЕЙ\n",
    "\n",
    "daily_returns = data_selected[[col for col in data_selected.columns if \"_RSI\" not in col]].pct_change()\n",
    "daily_returns.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "04fade92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log доходность\n",
    "log_returns = np.log(1 + daily_returns)\n",
    "new_data = data_selected.copy()\n",
    "\n",
    "for returns_roll in roll_return:\n",
    "    #считаю доходность за период returns_roll\n",
    "    rolling_returns = np.exp(log_returns.rolling(window=returns_roll).sum()) - 1\n",
    "    \n",
    "    #переименуем столбцы\n",
    "    rename_dict = {col: f\"{col}_return_{returns_roll}\" for col in rolling_returns.columns}\n",
    "    rolling_returns.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    # добавялю к основной таблице доходности\n",
    "    new_data = pd.concat([new_data, rolling_returns], axis=1)\n",
    "    new_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9efebea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#расчет скользящего СО и корреляции доходности\n",
    "columns_to_analyze = [_retur for _retur in new_data.columns if \"_retur\" in _retur]\n",
    "\n",
    "for window in window_sizes_std_corr:\n",
    "    rolling_stats = calculate_rolling_stats(new_data, columns_to_analyze, main_name, window=window)\n",
    "    \n",
    "    #переименую столцбы чтобы отражали размер окна\n",
    "    rolling_stats = rolling_stats.rename(columns=lambda x: f\"{x}_{window}\")\n",
    "    #обьединяю скользящую стат с исход данными\n",
    "    new_data = pd.concat([new_data, rolling_stats], axis=1)\n",
    "\n",
    "#удаляю пропуски\n",
    "new_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f0e20527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VRSK</th>\n",
       "      <th>JNPR</th>\n",
       "      <th>IT</th>\n",
       "      <th>CCI</th>\n",
       "      <th>KO</th>\n",
       "      <th>PG</th>\n",
       "      <th>DFS</th>\n",
       "      <th>GIS</th>\n",
       "      <th>RMD</th>\n",
       "      <th>DKS</th>\n",
       "      <th>...</th>\n",
       "      <th>PG_QCOM_rolling_corr_120</th>\n",
       "      <th>PG_BEN_rolling_corr_120</th>\n",
       "      <th>PG_SRE_rolling_corr_120</th>\n",
       "      <th>PG_PTC_rolling_corr_120</th>\n",
       "      <th>PG_CPB_rolling_corr_120</th>\n",
       "      <th>PG_TXRH_rolling_corr_120</th>\n",
       "      <th>PG_FBIN_rolling_corr_120</th>\n",
       "      <th>PG_Brent_rolling_corr_120</th>\n",
       "      <th>PG_Gold_rolling_corr_120</th>\n",
       "      <th>PG_SP_rolling_corr_120</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-28</th>\n",
       "      <td>68.510002</td>\n",
       "      <td>18.709999</td>\n",
       "      <td>60.919998</td>\n",
       "      <td>76.199997</td>\n",
       "      <td>39.020000</td>\n",
       "      <td>80.110001</td>\n",
       "      <td>51.009998</td>\n",
       "      <td>50.009998</td>\n",
       "      <td>50.740002</td>\n",
       "      <td>52.810001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101389</td>\n",
       "      <td>0.105894</td>\n",
       "      <td>0.344905</td>\n",
       "      <td>-0.147139</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.172896</td>\n",
       "      <td>0.093749</td>\n",
       "      <td>-0.123256</td>\n",
       "      <td>-0.123124</td>\n",
       "      <td>0.377431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-29</th>\n",
       "      <td>68.209999</td>\n",
       "      <td>18.980000</td>\n",
       "      <td>61.400002</td>\n",
       "      <td>75.839996</td>\n",
       "      <td>39.570000</td>\n",
       "      <td>81.459999</td>\n",
       "      <td>51.849998</td>\n",
       "      <td>50.770000</td>\n",
       "      <td>50.430000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091000</td>\n",
       "      <td>0.112098</td>\n",
       "      <td>0.393235</td>\n",
       "      <td>-0.144452</td>\n",
       "      <td>0.252294</td>\n",
       "      <td>0.162942</td>\n",
       "      <td>0.082023</td>\n",
       "      <td>-0.122560</td>\n",
       "      <td>-0.102936</td>\n",
       "      <td>0.378003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-30</th>\n",
       "      <td>68.680000</td>\n",
       "      <td>19.040001</td>\n",
       "      <td>60.959999</td>\n",
       "      <td>76.550003</td>\n",
       "      <td>39.880001</td>\n",
       "      <td>82.529999</td>\n",
       "      <td>52.740002</td>\n",
       "      <td>51.110001</td>\n",
       "      <td>51.400002</td>\n",
       "      <td>53.389999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067547</td>\n",
       "      <td>0.114144</td>\n",
       "      <td>0.426813</td>\n",
       "      <td>-0.144895</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.146078</td>\n",
       "      <td>0.067704</td>\n",
       "      <td>-0.100645</td>\n",
       "      <td>-0.068569</td>\n",
       "      <td>0.379296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-31</th>\n",
       "      <td>68.110001</td>\n",
       "      <td>18.660000</td>\n",
       "      <td>60.070000</td>\n",
       "      <td>76.620003</td>\n",
       "      <td>39.509998</td>\n",
       "      <td>81.199997</td>\n",
       "      <td>52.430000</td>\n",
       "      <td>50.650002</td>\n",
       "      <td>51.310001</td>\n",
       "      <td>53.209999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048312</td>\n",
       "      <td>0.120805</td>\n",
       "      <td>0.458407</td>\n",
       "      <td>-0.144428</td>\n",
       "      <td>0.241561</td>\n",
       "      <td>0.138034</td>\n",
       "      <td>0.061574</td>\n",
       "      <td>-0.090808</td>\n",
       "      <td>-0.053318</td>\n",
       "      <td>0.381840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01</th>\n",
       "      <td>68.790001</td>\n",
       "      <td>18.680000</td>\n",
       "      <td>59.189999</td>\n",
       "      <td>75.940002</td>\n",
       "      <td>39.570000</td>\n",
       "      <td>80.680000</td>\n",
       "      <td>51.869999</td>\n",
       "      <td>50.549999</td>\n",
       "      <td>51.570000</td>\n",
       "      <td>53.560001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032838</td>\n",
       "      <td>0.128707</td>\n",
       "      <td>0.494694</td>\n",
       "      <td>-0.143473</td>\n",
       "      <td>0.241546</td>\n",
       "      <td>0.135825</td>\n",
       "      <td>0.062019</td>\n",
       "      <td>-0.088309</td>\n",
       "      <td>-0.041476</td>\n",
       "      <td>0.390408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>241.229996</td>\n",
       "      <td>37.430000</td>\n",
       "      <td>468.760010</td>\n",
       "      <td>108.410004</td>\n",
       "      <td>59.759998</td>\n",
       "      <td>146.970001</td>\n",
       "      <td>97.750000</td>\n",
       "      <td>63.029999</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>152.270004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.455925</td>\n",
       "      <td>0.103864</td>\n",
       "      <td>-0.014393</td>\n",
       "      <td>0.196025</td>\n",
       "      <td>-0.230278</td>\n",
       "      <td>0.044657</td>\n",
       "      <td>0.499589</td>\n",
       "      <td>0.211953</td>\n",
       "      <td>-0.065344</td>\n",
       "      <td>0.537704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>243.009995</td>\n",
       "      <td>37.410000</td>\n",
       "      <td>469.160004</td>\n",
       "      <td>109.010002</td>\n",
       "      <td>59.529999</td>\n",
       "      <td>153.110001</td>\n",
       "      <td>99.769997</td>\n",
       "      <td>63.389999</td>\n",
       "      <td>177.320007</td>\n",
       "      <td>150.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.431279</td>\n",
       "      <td>0.103891</td>\n",
       "      <td>-0.018963</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>-0.219787</td>\n",
       "      <td>0.046060</td>\n",
       "      <td>0.494022</td>\n",
       "      <td>0.208562</td>\n",
       "      <td>-0.078689</td>\n",
       "      <td>0.527692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>245.000000</td>\n",
       "      <td>37.430000</td>\n",
       "      <td>470.970001</td>\n",
       "      <td>108.480003</td>\n",
       "      <td>59.799999</td>\n",
       "      <td>153.929993</td>\n",
       "      <td>100.879997</td>\n",
       "      <td>64.650002</td>\n",
       "      <td>175.470001</td>\n",
       "      <td>150.789993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400575</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>-0.016541</td>\n",
       "      <td>0.199065</td>\n",
       "      <td>-0.199961</td>\n",
       "      <td>0.046777</td>\n",
       "      <td>0.486816</td>\n",
       "      <td>0.203726</td>\n",
       "      <td>-0.089251</td>\n",
       "      <td>0.516312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>244.580002</td>\n",
       "      <td>37.330002</td>\n",
       "      <td>466.679993</td>\n",
       "      <td>108.970001</td>\n",
       "      <td>59.009998</td>\n",
       "      <td>152.399994</td>\n",
       "      <td>101.709999</td>\n",
       "      <td>63.860001</td>\n",
       "      <td>189.559998</td>\n",
       "      <td>153.149994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371266</td>\n",
       "      <td>0.104215</td>\n",
       "      <td>-0.023709</td>\n",
       "      <td>0.194758</td>\n",
       "      <td>-0.195381</td>\n",
       "      <td>0.039752</td>\n",
       "      <td>0.476646</td>\n",
       "      <td>0.204916</td>\n",
       "      <td>-0.097412</td>\n",
       "      <td>0.499935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>244.389999</td>\n",
       "      <td>37.220001</td>\n",
       "      <td>459.709991</td>\n",
       "      <td>110.769997</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>155.809998</td>\n",
       "      <td>104.239998</td>\n",
       "      <td>64.779999</td>\n",
       "      <td>187.979996</td>\n",
       "      <td>153.029999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337940</td>\n",
       "      <td>0.089220</td>\n",
       "      <td>-0.024279</td>\n",
       "      <td>0.188526</td>\n",
       "      <td>-0.168056</td>\n",
       "      <td>0.051884</td>\n",
       "      <td>0.464998</td>\n",
       "      <td>0.190225</td>\n",
       "      <td>-0.091786</td>\n",
       "      <td>0.481498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2567 rows × 672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  VRSK       JNPR          IT         CCI         KO  \\\n",
       "Date                                                                   \n",
       "2013-10-28   68.510002  18.709999   60.919998   76.199997  39.020000   \n",
       "2013-10-29   68.209999  18.980000   61.400002   75.839996  39.570000   \n",
       "2013-10-30   68.680000  19.040001   60.959999   76.550003  39.880001   \n",
       "2013-10-31   68.110001  18.660000   60.070000   76.620003  39.509998   \n",
       "2013-11-01   68.790001  18.680000   59.189999   75.940002  39.570000   \n",
       "...                ...        ...         ...         ...        ...   \n",
       "2024-01-22  241.229996  37.430000  468.760010  108.410004  59.759998   \n",
       "2024-01-23  243.009995  37.410000  469.160004  109.010002  59.529999   \n",
       "2024-01-24  245.000000  37.430000  470.970001  108.480003  59.799999   \n",
       "2024-01-25  244.580002  37.330002  466.679993  108.970001  59.009998   \n",
       "2024-01-26  244.389999  37.220001  459.709991  110.769997  59.250000   \n",
       "\n",
       "                    PG         DFS        GIS         RMD         DKS  ...  \\\n",
       "Date                                                                   ...   \n",
       "2013-10-28   80.110001   51.009998  50.009998   50.740002   52.810001  ...   \n",
       "2013-10-29   81.459999   51.849998  50.770000   50.430000   53.500000  ...   \n",
       "2013-10-30   82.529999   52.740002  51.110001   51.400002   53.389999  ...   \n",
       "2013-10-31   81.199997   52.430000  50.650002   51.310001   53.209999  ...   \n",
       "2013-11-01   80.680000   51.869999  50.549999   51.570000   53.560001  ...   \n",
       "...                ...         ...        ...         ...         ...  ...   \n",
       "2024-01-22  146.970001   97.750000  63.029999  174.000000  152.270004  ...   \n",
       "2024-01-23  153.110001   99.769997  63.389999  177.320007  150.250000  ...   \n",
       "2024-01-24  153.929993  100.879997  64.650002  175.470001  150.789993  ...   \n",
       "2024-01-25  152.399994  101.709999  63.860001  189.559998  153.149994  ...   \n",
       "2024-01-26  155.809998  104.239998  64.779999  187.979996  153.029999  ...   \n",
       "\n",
       "            PG_QCOM_rolling_corr_120  PG_BEN_rolling_corr_120  \\\n",
       "Date                                                            \n",
       "2013-10-28                 -0.101389                 0.105894   \n",
       "2013-10-29                 -0.091000                 0.112098   \n",
       "2013-10-30                 -0.067547                 0.114144   \n",
       "2013-10-31                 -0.048312                 0.120805   \n",
       "2013-11-01                 -0.032838                 0.128707   \n",
       "...                              ...                      ...   \n",
       "2024-01-22                 -0.455925                 0.103864   \n",
       "2024-01-23                 -0.431279                 0.103891   \n",
       "2024-01-24                 -0.400575                 0.108635   \n",
       "2024-01-25                 -0.371266                 0.104215   \n",
       "2024-01-26                 -0.337940                 0.089220   \n",
       "\n",
       "            PG_SRE_rolling_corr_120  PG_PTC_rolling_corr_120  \\\n",
       "Date                                                           \n",
       "2013-10-28                 0.344905                -0.147139   \n",
       "2013-10-29                 0.393235                -0.144452   \n",
       "2013-10-30                 0.426813                -0.144895   \n",
       "2013-10-31                 0.458407                -0.144428   \n",
       "2013-11-01                 0.494694                -0.143473   \n",
       "...                             ...                      ...   \n",
       "2024-01-22                -0.014393                 0.196025   \n",
       "2024-01-23                -0.018963                 0.193704   \n",
       "2024-01-24                -0.016541                 0.199065   \n",
       "2024-01-25                -0.023709                 0.194758   \n",
       "2024-01-26                -0.024279                 0.188526   \n",
       "\n",
       "            PG_CPB_rolling_corr_120  PG_TXRH_rolling_corr_120  \\\n",
       "Date                                                            \n",
       "2013-10-28                 0.253219                  0.172896   \n",
       "2013-10-29                 0.252294                  0.162942   \n",
       "2013-10-30                 0.243800                  0.146078   \n",
       "2013-10-31                 0.241561                  0.138034   \n",
       "2013-11-01                 0.241546                  0.135825   \n",
       "...                             ...                       ...   \n",
       "2024-01-22                -0.230278                  0.044657   \n",
       "2024-01-23                -0.219787                  0.046060   \n",
       "2024-01-24                -0.199961                  0.046777   \n",
       "2024-01-25                -0.195381                  0.039752   \n",
       "2024-01-26                -0.168056                  0.051884   \n",
       "\n",
       "            PG_FBIN_rolling_corr_120  PG_Brent_rolling_corr_120  \\\n",
       "Date                                                              \n",
       "2013-10-28                  0.093749                  -0.123256   \n",
       "2013-10-29                  0.082023                  -0.122560   \n",
       "2013-10-30                  0.067704                  -0.100645   \n",
       "2013-10-31                  0.061574                  -0.090808   \n",
       "2013-11-01                  0.062019                  -0.088309   \n",
       "...                              ...                        ...   \n",
       "2024-01-22                  0.499589                   0.211953   \n",
       "2024-01-23                  0.494022                   0.208562   \n",
       "2024-01-24                  0.486816                   0.203726   \n",
       "2024-01-25                  0.476646                   0.204916   \n",
       "2024-01-26                  0.464998                   0.190225   \n",
       "\n",
       "            PG_Gold_rolling_corr_120  PG_SP_rolling_corr_120  \n",
       "Date                                                          \n",
       "2013-10-28                 -0.123124                0.377431  \n",
       "2013-10-29                 -0.102936                0.378003  \n",
       "2013-10-30                 -0.068569                0.379296  \n",
       "2013-10-31                 -0.053318                0.381840  \n",
       "2013-11-01                 -0.041476                0.390408  \n",
       "...                              ...                     ...  \n",
       "2024-01-22                 -0.065344                0.537704  \n",
       "2024-01-23                 -0.078689                0.527692  \n",
       "2024-01-24                 -0.089251                0.516312  \n",
       "2024-01-25                 -0.097412                0.499935  \n",
       "2024-01-26                 -0.091786                0.481498  \n",
       "\n",
       "[2567 rows x 672 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc34e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c5f4f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#подготовка данных к методу ближайших соседей \n",
    "data_neighbor = new_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e74da6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#переворачиваем табл\n",
    "\n",
    "data_neighbor = data_neighbor.reindex(index=data_neighbor.index[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "af16ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сортирую признаки чтобы применить разные обьекты стандартизации\n",
    "rsi_columns = [i for i in data_neighbor.columns if \"_RSI\" in i]\n",
    "return_columns = [i for i in data_neighbor.columns if \"_return\" in i]\n",
    "std_columns = [i for i in data_neighbor.columns if \"_rolling_std\" in i]\n",
    "corr_columns = [i for i in data_neighbor.columns if \"_rolling_corr\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "cbc75615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_19204\\2980127850.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])\n"
     ]
    }
   ],
   "source": [
    "#Нормализованный фрейм\n",
    "new_data_scaler = pd.DataFrame(index=data_neighbor.index)\n",
    "\n",
    "new_data_scaler[rsi_columns] = scaler_RSI.fit_transform(data_neighbor[rsi_columns])\n",
    "new_data_scaler[return_columns] = scaler_return.fit_transform(data_neighbor[return_columns])\n",
    "new_data_scaler[std_columns] = scaler_std.fit_transform(data_neighbor[std_columns])\n",
    "new_data_scaler[corr_columns] = scaler_corr.fit_transform(data_neighbor[corr_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c71f59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5c47487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаю наблюдения  в виде окон  \n",
    "window_data = create_rolling_windows(new_data_scaler, 100)\n",
    "data_matrix = np.array(window_data)\n",
    "data_matrix = data_matrix.reshape(-1, data_matrix.shape[1]*data_matrix.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ae6501ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = pca.fit_transform(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c88932cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#целевое наблюдение \n",
    "y = reduced_data[500].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4efec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "fa489748",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = pd.Timestamp('2016-05-18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "1aef0dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-05-18 00:00:00')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "b002b4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1927"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_neighbor.index.get_loc(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d4521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "6d135756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(n_neighbors=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(n_neighbors=300)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(n_neighbors=300)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7164a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#в ычисление расстояний и индексов ближайших соседей\n",
    "distances, indices = knn.kneighbors(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875a370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b85b89c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#получение лага для прогноза\n",
    "predict_days = (new_data_rebalance[0][1] - new_data_rebalance[0][0]).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "5bcb680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_distribytion = []\n",
    "#не рассматриваю ближашие и слишком удаленные индексы\n",
    "for idx in indices.tolist()[0][15:150]:\n",
    "    #находу тек цену\n",
    "    current_price = data_neighbor.iloc[:, :len(data_selected_1.columns)][main_name][idx]\n",
    "    #беру дату текущей цены\n",
    "    current_index = data_neighbor.iloc[:, :len(data_selected_1.columns)][main_name].index[idx]\n",
    "    #беру лаг от текущего индекса\n",
    "    future_index = current_index + pd.DateOffset(days = predict_days)\n",
    "    # Определяем диапазон дат: от future_index - X дней до future_index + X дней\n",
    "    #беру разные лаги (в отриц сторону больше) чтобы не переоценить доходнотсь и недооценить риски\n",
    "    date_range = pd.date_range(start=future_index - pd.DateOffset(days=30), end=future_index + pd.DateOffset(days=10))\n",
    "    # фильтрую, чтобы сохранять только те даты, которые существуют в индексе\n",
    "    existing_dates = date_range[date_range.isin(data_neighbor.index)]\n",
    "    #считаю доходности\n",
    "    local_distribution = list((data_neighbor.loc[existing_dates, main_name] / current_price)-1)\n",
    "    global_distribytion.append(local_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "4874bd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-09-28 00:00:00')"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "8cb1daa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-03-03 00:00:00')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "25b46a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#обьединяю все доходности\n",
    "distrib = [g for glob_i in global_distribytion for g in glob_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3567fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вычисляю среднее (учитывая асимметрию)\n",
    "mean_value = choose_metric(distrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "7853bd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04014574616974376"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a6b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "331a1a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6)) \n",
    "\n",
    "sns.histplot(distrib, kde=True, stat=\"density\", linewidth=0, color='blue', alpha=0.6)\n",
    "\n",
    "plt.title('Распределение ожидаемых доходностей')  \n",
    "plt.xlabel('Доходность')  \n",
    "plt.ylabel('Плотность') \n",
    "plt.grid(True)  #добавиьь сетку\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf55977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "83ed9d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#для проверки нахожу фактичекую доходность\n",
    "#цена на тек\n",
    "local_price = data_neighbor.iloc[500, :][main_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "bf56ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#дуюущие цены \n",
    "#нахожу индекс столбца по имени\n",
    "col_index = data_neighbor.columns.get_loc(main_name)\n",
    "future_prices = data_neighbor.iloc[100 - predict_days:100 - predict_days + 10, col_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cca53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_neighbor.iloc[500 - predict_days:500 - predict_days + 10, col_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4defa0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1271861863754148"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((future_prices / local_price)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "a6cf376b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-09-28 00:00:00')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "a263a06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-02-25 00:00:00')"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_index + pd.DateOffset(days = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cabfe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f544b867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ca8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350db699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1d2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c77653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252b948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb8ebcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5750a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e70cfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33aa2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
